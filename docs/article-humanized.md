# NanoClaw：Skills协议驱动的AI Agent架构革新

## 一、引言

谈到AI Agent开发工具，有个问题绕不开：信任。

OpenClaw是个令人印象深刻的项目——50万行代码、53个配置文件、70多个依赖。但问题来了：一个需要接入你的WhatsApp、访问个人数据、在你服务器上执行代码的系统，你真能理解它的每一行吗？万一发生提示词注入攻击，你敢拍着胸脯说"我知道系统的边界在哪"吗？

NanoClaw给出了另一种答案。约500行TypeScript核心代码，实现了OpenClaw的核心功能。但NanoClaw真正有趣的地方**不是"小"**——而是它通过**Skills协议**重新定义了功能扩展的方式，从而改变了我们对"软件定制"的理解。

这篇文章不会用宏大的叙事包装这个系统。我们会深入到代码层面，看看NanoClaw如何用极简的架构实现物理级的安全隔离，以及更重要的——**Skills协议如何让我们从"代码库膨胀"走向"按需自修改"**。

## 二、核心架构简析

NanoClaw的核心架构可以概括为三个关键词：容器隔离、异步持久化、防御性编程。我们简要看看每个设计的核心思想。

### 2.1 容器隔离

NanoClaw摒弃了传统的应用层权限模型。它的安全假设很简单：**所有外部输入都不可信**。

每次Agent调用时，NanoClaw都会创建一个新的Linux容器。关键设计在`src/container-runner.ts`的`buildVolumeMounts`函数中：

```typescript
if (isMain) {
  // Main group获得项目根目录只读权限
  mounts.push({
    hostPath: projectRoot,
    containerPath: '/workspace/project',
    readonly: true,
  });
} else {
  // 其他群组只能访问自己的文件夹
  mounts.push({
    hostPath: groupDir,
    containerPath: '/workspace/group',
    readonly: false,
  });
}
```

核心原则：显式挂载 + 最小权限。只有明确挂载的目录才能访问，且默认只读。即使某个群组内的Agent被恶意诱导，也无法读取其他群组的隐私数据——这是操作系统级别的权限墙，不是应用层的安全假设。

### 2.2 异步消息循环

NanoClaw需要解决一个经典矛盾：WhatsApp消息是高频、不可靠的即时通讯输入，而Claude Agent SDK调用是高延迟、高消耗的大模型推理。直接耦合会导致消息丢失、API限流、系统不稳定。

解耦方案是引入SQLite作为持久化层：

```
WhatsApp -> SQLite(持久化) -> Polling Loop -> Container(Claude SDK) -> Response
```

关键设计决策在`src/index.ts`的`startMessageLoop`中：

1. **立即advance cursor**：消息一旦读取就更新`lastTimestamp`，防止崩溃重启后重复处理
2. **Cursor分离**：`lastTimestamp`（已读消息游标）与`lastAgentTimestamp`（已处理消息游标）分离，支持非trigger消息累积为上下文
3. **Crash Recovery**：`recoverPendingMessages`在启动时检查未处理消息

这种设计让NanoClaw可以在崩溃后无缝恢复，保证每条消息都被处理且只被处理一次。

### 2.3 Issue #30的教训

2024年，NanoClaw遇到一个生产环境事故：用户要求用芬兰语设置一个提醒，结果在32秒内连续收到了21条一模一样的确认消息，且AI在循环中途完全丢失了芬兰语的上下文。

根本原因：`container/agent-runner/src/index.ts`在调用SDK的`query()`函数时，未设置`maxTurns`参数：

```typescript
// 错误：未设置maxTurns
for await (const message of query({ prompt, options: {} })) {
  // 处理消息...
}
```

问题机制：Agent调用发送消息工具 -> 工具返回"消息已加入交付队列"的模糊响应 -> SDK解读为"任务未完成，需继续" -> 无`maxTurns`限制导致无限循环 -> 每次循环消耗Token -> 旧对话历史被挤出上下文 -> 芬兰语指令丢失。

修复方案很简单：

```typescript
for await (const message of query({
  prompt,
  options: { maxTurns: 10 }  // 最多10轮交互
})) {
  // 处理消息...
}
```

工程教训：在不确定的模型推理过程中，必须在代码层面强制施加确定性的安全终止条件。永远不要假设AI会自己知道何时停止。

---

## 三、Skills协议

如果说容器隔离和异步消息循环是NanoClaw的"基本功"，那么Skills协议就是它的"独门绝技"。

### 3.1 开源协作模式的困境

让我们直面一个被长期忽视的问题：现代开源软件的复杂性危机。

假设你想要为一个AI Agent平台添加Telegram支持。在传统模式下，这意味着代码层面的膨胀：新增adapter层、依赖管理、配置层膨胀、条件路由逻辑。每加一个平台，就多一套代码。

配置层面也会蔓延：config.yaml随着平台增加而无限膨胀。测试矩阵爆炸：3个平台 × 10个功能 × 5种配置 = 150个测试场景。

认知负荷累积：新贡献者需要理解通用路由层、WhatsApp适配器、Telegram适配器、配置系统、依赖注入框架——1050行代码，5个抽象层次，可能需要1-2周才能完全理解。

但在NanoClaw的模式下，你只需要理解当前生成的代码（约200行）和如何执行skill。

这就是传统模式的问题：它迫使每个用户为所有用户的功能买单——认知负荷、代码体积、配置复杂度，都是如此。

### 3.2 NanoClaw的激进选择

面对上述结构性困境，NanoClaw做出了一个在当时看来非常激进的选择：

> "Don't add features. Add skills."

这句话不是营销话术，而是一个根本性的架构宣言：不再维护一个试图满足所有人的通用代码库，而是让每个用户拥有为自己的需求定制的专用代码库。

这不是"减少功能"，而是"功能的生成方式发生了根本性改变"。

### 3.3 Skills协议详解

**什么是Skill**

Skill不是：
- 可执行的二进制插件
- 传统意义上的"插件"
- 简单的配置文件或脚本

Skill是：
- 用自然语言编写的专家指令
- 指导Claude Code进行源代码转换的"菜谱"
- 声明式的代码生成规范

**Skill文件结构**

文件位置：`.claude/skills/{skill-name}/SKILL.md`

包含：
1. **元数据层（YAML Frontmatter）**：skill_id, name, version, description, tags
2. **完整指令层（Markdown主体）**：Overview, Prerequisites, Step-by-Step Guide
3. **关联资源层**：预设脚本、测试用例

**执行流程**

1. **元数据加载**：系统启动时只加载YAML Frontmatter（约50-100 tokens/skill）
2. **意图匹配**：用户输入`/add-telegram`，系统匹配skill_id
3. **完整内容加载**：按需加载完整Markdown内容（约2000-5000 tokens）
4. **步骤执行**：Claude解析并执行每个Step（Action → Code → Verification → Rollback）
5. **结果验证**：执行最终验证，通知用户结果

**Progressive Disclosure（渐进式暴露）**

这是Skills协议的核心优化策略：

- **空闲状态**：只加载元数据（1000个skills = 约75K tokens）
- **执行单个skill**：加载元数据 + 该skill的完整指令
- **Token效率**：相比传统全量加载，节省98%的初始上下文开销

这使得系统可以同时挂载成百上千个skills而不影响性能。

---

## 四、实践建议

### 4.1 何时考虑类似Skills的架构

**适用场景**：
- 功能高度可定制化，每个用户需求差异大
- 代码库膨胀导致维护困难
- 需要快速响应多样化需求
- 团队有能力维护多个定制化版本

**不适用场景**：
- 功能标准化，用户定制需求少
- 团队规模小，无法维护多个版本
- 需要严格的版本控制和兼容性保证

### 4.2 渐进式采用策略

不要试图一次性完全转向Skills模式。建议分阶段渐进式采用：

**阶段1：实验（1-2个skills，1-2个月）**
- 选择1-2个最常用的定制需求
- 编写对应的Skill文件
- 在小范围内测试（例如内部团队）

**阶段2：验证（5-10个skills，3-6个月）**
- 扩展Skill库到覆盖主要使用场景
- 建立Skill编写规范和最佳实践
- 收集用户反馈并迭代

**阶段3：全面采用（所有定制通过skill，6-12个月）**
- 所有新功能通过Skill实现
- 冻结原有插件/扩展系统的开发
- 提供迁移路径帮助现有用户迁移

### 4.3 关键成功因素

基于NanoClaw的实践，以下是成功实施Skills模式的关键因素：

**1. 清晰的元数据**
- skill的描述要准确、完整
- 明确使用场景和先决条件
- 提供清晰的预期效果

**2. 详尽的指令**
- 步骤要具体、可执行
- 提供验证方法
- 包含回滚方案

**3. 持续的测试**
- 定期自动执行所有Skills，验证它们仍然有效
- 当NanoClaw更新时，测试所有Skills是否仍然兼容
- 建立机制让用户报告失败的Skills

---

## 五、结语

NanoClaw给我们展示了一种可能性：当AI能够理解和修改代码，软件开发会变成什么样？

**核心洞察回顾**

容器隔离不是"可选安全"，而是"必需基础"。当AI Agent拥有系统级执行权限时，应用层的安全假设已经失效。NanoClaw的物理级容器隔离应该成为所有类似系统的标配，而不是可选功能。

Skills协议代表了一种新的开源协作范式。从"提交PR"到"执行Skill"，从"共享代码"到"共享知识"，从"通用框架"到"专用定制"——这种转变可能预示着一个新时代的到来：在这个时代，软件的"功能"不再是预先定义好的，而是根据需要实时生成的。

防御性编程在AI时代变得更加重要。Issue #30的教训告诉我们：在不确定的模型推理过程中，必须在代码层面强制施加确定性的安全终止条件。永远不要假设AI会自己知道何时停止。

**给工程师的思考**

不要只看NanoClaw的具体实现，要看它背后的设计思想：

你的系统在面对不可信输入时，有多少信心？如果有一个恶意的AI Agent试图攻击你的系统，它能造成多大的破坏？NanoClaw的答案是："即使Agent被攻破，它也只能访问明确挂载的目录，无法影响其他用户或系统本身。"

你的系统是否有"每个用户都想要不同功能"的问题？如果是，你是如何解决这个问题的？是通过不断增加配置选项，还是通过插件系统？NanoClaw的答案是："我们不维护通用代码库，而是让每个用户拥有自己的专用代码库。"

你的系统是否能够"自我修改"？当需求变化时，你的系统能否自动适应，还是需要人工干预？NanoClaw的答案是："通过执行Skill，系统可以自动添加新功能，无需等待外部开发。"

**最后的思考**

Skills协议可能只是一个开始。未来，或许所有的软件都是"自修改"的——它们不是被预先编写好的，而是根据需要实时生成的。在这个未来里，程序员的职责可能不再是"编写代码"，而是"编写生成代码的指令"——也就是我们今天所说的Skills。

问题是：你准备好迎接这个未来了吗？
